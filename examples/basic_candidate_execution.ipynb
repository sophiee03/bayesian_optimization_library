{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7cedb7f8",
   "metadata": {},
   "source": [
    "# BASIC CANDIDATE EXECUTION WITH YPROV4ML"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e3a31c2",
   "metadata": {},
   "source": [
    "Imports needed for BayesianOptimization and candidates execution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "98b3c3db",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys, os\n",
    "from bayesopt import *\n",
    "sys.path.insert(0, os.path.abspath(os.path.join(os.path.join(os.getcwd()), '..')))\n",
    "import etl.extractors.provenance_extractor as pe\n",
    "from typing import Dict, List, Optional\n",
    "import csv\n",
    "from datetime import datetime\n",
    "import torch, torchvision, yprov4ml\n",
    "import torch.optim as optim\n",
    "from tqdm import tqdm\n",
    "import torchvision.transforms as transforms\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import netCDF4 as nc"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73377354",
   "metadata": {},
   "source": [
    "### CANDIDATE GENERATION\n",
    "Here we use the run method to perform Bayesian Optimization and obtain a candidate.\n",
    "\n",
    "(for detailed explanation of the workflow see the detailed_cand_generation.ipynb notebook)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "da72a5b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_needed = {\n",
    "    'input': ['DROPOUT', 'BATCH_SIZE', 'EPOCHS', 'LR', 'MODEL_SIZE'],\n",
    "    'output': ['accuracy', 'emissions']\n",
    "}\n",
    "\n",
    "extractor = pe.ProvenanceExtractor('../test/prov_25', data_needed)\n",
    "inp, out = extractor.extract_all()      # cols are parameters/metrics, rows are runs\n",
    "\n",
    "bayesopt = BayesianOptimizer(OptimizationConfig(\n",
    "    data_needed['output'],\n",
    "    data_needed['input'],\n",
    "    ['MAX', 'MIN'],\n",
    "    ground_truth_dim=len(inp),\n",
    "    n_candidates=1,\n",
    "    n_restarts=10,\n",
    "    raw_samples=200,\n",
    "    optimizers='optimize_acqf',\n",
    "    acqf='ucb',\n",
    "    beta=1.5,\n",
    "    verbose=False\n",
    "))\n",
    "\n",
    "data = {\n",
    "    'parameters': inp,\n",
    "    'metrics': out\n",
    "}\n",
    "\n",
    "# res will be a OptimizationResults instance\n",
    "res = bayesopt.run(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9fdd9b5",
   "metadata": {},
   "source": [
    "### CANDIDATE EXECUTION\n",
    "In this block the candidate will be executed with yprov4ml (to see the yprov functionality refer to their documentation). \n",
    "\n",
    "NB: for now if the candidate generated has a twin there could be errors in returning the accuracy and emissions, if you notice a 'duplicate candidate' change the _0 to _1 in the _emission call"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9aae5a39",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[codecarbon WARNING @ 21:23:26] Multiple instances of codecarbon are allowed to run at the same time.\n",
      "100%|██████████| 1613/1613 [02:47<00:00,  9.62it/s]\n",
      "100%|██████████| 1613/1613 [03:14<00:00,  8.30it/s]\n",
      "100%|██████████| 1613/1613 [03:20<00:00,  8.05it/s]\n",
      "100%|██████████| 1613/1613 [03:23<00:00,  7.92it/s]\n",
      "100%|██████████| 1613/1613 [03:18<00:00,  8.12it/s]\n",
      "100%|██████████| 1613/1613 [03:19<00:00,  8.07it/s]\n",
      "100%|██████████| 1613/1613 [03:14<00:00,  8.28it/s]\n",
      "100%|██████████| 1613/1613 [03:40<00:00,  7.30it/s]\n",
      "100%|██████████| 1613/1613 [03:23<00:00,  7.94it/s]\n",
      "100%|██████████| 1613/1613 [03:23<00:00,  7.93it/s]\n",
      "100%|██████████| 323/323 [00:07<00:00, 40.56it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 10.0 %\n",
      "Emissions: 0.06714221835136414\n"
     ]
    }
   ],
   "source": [
    "class Net(nn.Module):\n",
    "    def __init__(self, model_size, dropout):\n",
    "        super(Net, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(3, 32, 3, 1)\n",
    "        self.conv2 = nn.Conv2d(32, 64, 3, 1)\n",
    "        self.dropout1 = nn.Dropout(dropout)\n",
    "        self.dropout2 = nn.Dropout(dropout)\n",
    "\n",
    "        def get_layer_sizes(model_size): \n",
    "            if model_size == \"small\": \n",
    "                return 64, 32\n",
    "            elif model_size == \"medium\": \n",
    "                return 512, 256\n",
    "            else: \n",
    "                return 1024, 256\n",
    "\n",
    "        l1, l2 = get_layer_sizes(model_size)\n",
    "\n",
    "        self.fc1 = nn.Linear(12544, l1)\n",
    "        self.fc2 = nn.Linear(l1, l2)\n",
    "        self.fc3 = nn.Linear(l2, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.conv2(x)\n",
    "        x = F.relu(x)\n",
    "        x = F.max_pool2d(x, 2)\n",
    "        x = self.dropout1(x)\n",
    "        x = torch.flatten(x, 1)\n",
    "        x = self.fc1(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.dropout2(x)\n",
    "        x = self.fc2(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.dropout1(x)\n",
    "        x = self.fc3(x)\n",
    "        output = F.log_softmax(x, dim=1)\n",
    "        return output\n",
    "\n",
    "def train(lr, epochs, batch_size, dropout, model_size):\n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "    transform = transforms.Compose([transforms.ToTensor(), transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])\n",
    "    dataset = torchvision.datasets.CIFAR10(root='./data', train=True, download=True, transform=transform)\n",
    "    trainloader = torch.utils.data.DataLoader(dataset, batch_size=batch_size)\n",
    "\n",
    "    model = Net(model_size, dropout=dropout).to(device)\n",
    "    optimizer = optim.Adam(model.parameters(), lr=lr)\n",
    "    criterion = torch.nn.CrossEntropyLoss().to(device)\n",
    "    scheduler = None\n",
    "\n",
    "    model.train()\n",
    "\n",
    "    losses = []\n",
    "    for _ in range(epochs): \n",
    "        for data in tqdm(trainloader):\n",
    "            inputs, labels = data[0].to(device), data[1].to(device)\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            losses.append(loss.item())\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            if scheduler is not None:\n",
    "                scheduler.step()\n",
    "    yprov4ml.log_carbon_metrics(yprov4ml.Context.TRAINING, step=0)\n",
    "    return model\n",
    "\n",
    "def emissions_(expdir_path):\n",
    "    fp=f'./{expdir_path}/metrics_GR0/emissions_Context.TRAINING_GR0.nc'\n",
    "    data = nc.Dataset(fp)\n",
    "    return data[\"values\"][:]\n",
    "\n",
    "def validate(model, batch_size=128):\n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "    transform = transforms.Compose([transforms.ToTensor(), transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])\n",
    "    dataset = torchvision.datasets.CIFAR10(root='./data', train=False, download=True, transform=transform)\n",
    "    testloader = torch.utils.data.DataLoader(dataset, batch_size=batch_size, shuffle=False)\n",
    "    model.eval()\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    with torch.no_grad():\n",
    "        for data in tqdm(testloader):\n",
    "            images, labels = data[0].to(device), data[1].to(device)\n",
    "            outputs = model(images)\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "\n",
    "    return correct / total\n",
    "\n",
    "def handle_modelsize(n: float):\n",
    "    if n <= 3700506.0:      #small\n",
    "        return 'small'\n",
    "    elif n <= 9853386.0:    #medium\n",
    "        return 'medium'\n",
    "    else:                   #large\n",
    "        return 'large'\n",
    "\n",
    "exec_results = []\n",
    "for candidate in res.candidates:\n",
    "    candidate[4] = handle_modelsize(candidate[4])   #change to small/medium/large the modelsize\n",
    "    yprov4ml.start_run(\n",
    "        prov_user_namespace=\"www.example.org\",\n",
    "        experiment_name=f\"{round(candidate[3], 4)}_{int(candidate[2])}_{int(candidate[1])}_{round(candidate[0], 2)}_{candidate[4]}\", \n",
    "        provenance_save_dir=\"../test/prov_candidates_executed\",     # change the folder in which you want to save the candidate executed\n",
    "        save_after_n_logs=100,\n",
    "        collect_all_processes=False, \n",
    "        disable_codecarbon=False, \n",
    "        metrics_file_type=yprov4ml.MetricsType.NETCDF,\n",
    "    )\n",
    "\n",
    "    yprov4ml.log_param(\"MODEL_SIZE\", candidate[4], yprov4ml.Context.TRAINING)\n",
    "    yprov4ml.log_param(\"DROPOUT\", candidate[0], yprov4ml.Context.TRAINING)\n",
    "    yprov4ml.log_param(\"BATCH_SIZE\", candidate[1], yprov4ml.Context.TRAINING)\n",
    "    yprov4ml.log_param(\"EPOCHS\", candidate[2], yprov4ml.Context.TRAINING)\n",
    "    yprov4ml.log_param(\"LR\", candidate[3], yprov4ml.Context.TRAINING)\n",
    "\n",
    "    trained_model = train(candidate[3], int(candidate[2]), int(candidate[1]), candidate[0], candidate[4])\n",
    "    acc = validate(trained_model, int(candidate[1]))\n",
    "\n",
    "    yprov4ml.log_param(\"accuracy\", acc, yprov4ml.Context.TESTING)\n",
    "\n",
    "    yprov4ml.end_run(\n",
    "        create_graph=False,\n",
    "        create_svg=False,\n",
    "        crate_ro_crate=False\n",
    "    )\n",
    "\n",
    "    print(f'Accuracy: {100 * acc} %')\n",
    "    em = emissions_(f\"../test/prov_candidates_executed/{round(candidate[3], 4)}_{int(candidate[2])}_{int(candidate[1])}_{round(candidate[0], 2)}_{candidate[4]}_0\")[0]\n",
    "    print(f'Emissions: {em}')\n",
    "    exec_results.append([acc, em])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a99a223d",
   "metadata": {},
   "source": [
    "### SAVE CANDIDATES AND THEIR RESULTS TO A CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9f3fe7bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CSVResults:\n",
    "    \"\"\"class to write to a csv file the results obtained from Bayesian Optimization\n",
    "    \n",
    "    Attributes:\n",
    "        csv_path (str): path for the file to be accessed/created\n",
    "        parameter_names (List(str)): names of the parameters optimized (for headers)\n",
    "        metrics_names (List(str)): names of the metrics (for headers)\n",
    "        metrics_estim_names (List(str)): names of the estimated metrics (for headers)\n",
    "    \"\"\"\n",
    "    def __init__(self, headers: Dict[str, List[str]], path: str):\n",
    "        self.csv_path = path\n",
    "        self.parameter_names = headers['parameters']\n",
    "        self.metrics_names = headers['metrics']\n",
    "        self.metrics_estim_names = [f'estimated {m}' for m in headers['metrics']]\n",
    "        self.ensure_exists()\n",
    "\n",
    "    def build_headers(self):\n",
    "        headers = ['timestamp', 'candidate_id', 'acq_value', 'optimizer', 'acqf', 'n_restarts', 'raw_samples']\n",
    "\n",
    "        headers.extend(self.parameter_names)\n",
    "\n",
    "        for metric in self.metrics_estim_names:\n",
    "            headers.append(f'{metric} (mean)')\n",
    "            headers.append(f'{metric} (std)')\n",
    "\n",
    "        headers.append('execution status')\n",
    "        headers.extend(self.metrics_names)\n",
    "        return headers\n",
    "\n",
    "    def ensure_exists(self):\n",
    "        if not os.path.exists(self.csv_path):\n",
    "            with open(self.csv_path, 'w', newline='') as f:\n",
    "                writer = csv.writer(f)\n",
    "                writer.writerow(self.build_headers())\n",
    "    \n",
    "    def log_candidates(self, results: OptimizationResults, config: OptimizationConfig, exec_results: Optional[List[List]]=None):\n",
    "        timestamp = datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\")\n",
    "\n",
    "        # shape [n_candidates x n_metrics]\n",
    "        mean = results.posterior.mean.detach().numpy()\n",
    "        std = results.posterior.variance.sqrt().detach().numpy()\n",
    "\n",
    "        rows_to_write = []\n",
    "\n",
    "        if isinstance(results.acq_values, list):\n",
    "            acq_val = results.acq_values\n",
    "        else:\n",
    "            acq_val = [results.acq_values]*len(results.candidates)\n",
    "\n",
    "        for i, candidate in enumerate(results.candidates):\n",
    "            if isinstance(candidate, torch.Tensor):\n",
    "                candidate = candidate.tolist()\n",
    "\n",
    "            row = [timestamp, i+1, round(acq_val[i], 6), config.optimizers, config.acqf, config.n_restarts, config.raw_samples]\n",
    "            for param_val in candidate:\n",
    "                if isinstance(param_val, float):\n",
    "                    row.append(round(param_val, 6))\n",
    "                else:\n",
    "                    row.append(param_val)\n",
    "\n",
    "            for m in range(len(self.metrics_estim_names)):\n",
    "                if m < mean.shape[1]:\n",
    "                    row.append(round(mean[i][m].item(), 6))\n",
    "                    row.append(round(std[i][m].item(), 6))\n",
    "                else:\n",
    "                    row.extend([None, None])\n",
    "            \n",
    "            if exec_results and i < len(exec_results):\n",
    "                row.append('executed')\n",
    "                for m in range(len(self.metrics_names)):\n",
    "                    value = exec_results[i][m]\n",
    "                    if isinstance(value, float):\n",
    "                        row.append(round(value, 6))\n",
    "                    else:\n",
    "                        row.append(value)\n",
    "            else:\n",
    "                row.append('not_executed')\n",
    "                row.extend([None]*len(self.metrics_names))\n",
    "            \n",
    "            rows_to_write.append(row)\n",
    "\n",
    "        self.append_rows(rows_to_write)\n",
    "\n",
    "    def append_rows(self, rows: List[List]):\n",
    "        with open(self.csv_path, 'a', newline='') as f:\n",
    "            writer = csv.writer(f)\n",
    "            writer.writerows(rows)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "88d6972b",
   "metadata": {},
   "outputs": [],
   "source": [
    "csv_saver = CSVResults(\n",
    "    {'parameters': ['DROPOUT', 'BATCH_SIZE', 'EPOCHS', 'LR', 'MODEL_SIZE'], \n",
    "    'metrics': ['accuracy', 'emissions']},\n",
    "    './candidates_executed.csv')\n",
    "csv_saver.log_candidates(res, bayesopt.config, exec_results)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3c1d070",
   "metadata": {},
   "source": [
    "### VISUALIZE RESULTS"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "035c4db6",
   "metadata": {},
   "source": [
    "In the following table we can observe the results obtained by generate, estimate and execute candidates.\n",
    "\n",
    "NB: the estimated emission is negative because it's a metric to minimize (so we have to consider it as positive)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "08d467b0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>timestamp</th>\n",
       "      <th>candidate_id</th>\n",
       "      <th>acq_value</th>\n",
       "      <th>optimizer</th>\n",
       "      <th>acqf</th>\n",
       "      <th>n_restarts</th>\n",
       "      <th>raw_samples</th>\n",
       "      <th>DROPOUT</th>\n",
       "      <th>BATCH_SIZE</th>\n",
       "      <th>EPOCHS</th>\n",
       "      <th>LR</th>\n",
       "      <th>MODEL_SIZE</th>\n",
       "      <th>estimated accuracy (mean)</th>\n",
       "      <th>estimated accuracy (std)</th>\n",
       "      <th>estimated emissions (mean)</th>\n",
       "      <th>estimated emissions (std)</th>\n",
       "      <th>execution status</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>emissions</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2026-01-15 21:56:51</td>\n",
       "      <td>1</td>\n",
       "      <td>0.377749</td>\n",
       "      <td>optimize_acqf</td>\n",
       "      <td>ucb</td>\n",
       "      <td>10</td>\n",
       "      <td>200</td>\n",
       "      <td>0.498863</td>\n",
       "      <td>31.004065</td>\n",
       "      <td>10.035223</td>\n",
       "      <td>0.084505</td>\n",
       "      <td>large</td>\n",
       "      <td>0.737886</td>\n",
       "      <td>0.017958</td>\n",
       "      <td>-0.004368</td>\n",
       "      <td>0.000387</td>\n",
       "      <td>executed</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.067142</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             timestamp  candidate_id  acq_value      optimizer acqf  \\\n",
       "0  2026-01-15 21:56:51             1   0.377749  optimize_acqf  ucb   \n",
       "\n",
       "   n_restarts  raw_samples   DROPOUT  BATCH_SIZE     EPOCHS        LR  \\\n",
       "0          10          200  0.498863   31.004065  10.035223  0.084505   \n",
       "\n",
       "  MODEL_SIZE  estimated accuracy (mean)  estimated accuracy (std)  \\\n",
       "0      large                   0.737886                  0.017958   \n",
       "\n",
       "   estimated emissions (mean)  estimated emissions (std) execution status  \\\n",
       "0                   -0.004368                   0.000387         executed   \n",
       "\n",
       "   accuracy  emissions  \n",
       "0       0.1   0.067142  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv('./candidates_executed.csv')\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a03d3b7",
   "metadata": {},
   "source": [
    "### RE-EXECUTE APPENDING CANDIDATE\n",
    "Now we append the result that we obtained and re-generate candidates with the updated training dataset\n",
    "\n",
    "NB: if you change model with this type of iterative execution there could be problems "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b266d9f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_size = 824862.0 if res.candidates[0][4] == 'small' else 6576330.0 if res.candidates[0][4] == 'medium' else 13130442.0\n",
    "new_data = {\n",
    "    'parameters': [[res.candidates[0][0], res.candidates[0][1], res.candidates[0][2], res.candidates[0][3], model_size]],\n",
    "    'metrics': exec_results\n",
    "}\n",
    "\n",
    "bayesopt.update_training_set(new_data)\n",
    "second_res = bayesopt.run()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f5dde6c",
   "metadata": {},
   "source": [
    "### SAVE THE NEW CANDIDATE WITHOUT EXECUTION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2f6b6558",
   "metadata": {},
   "outputs": [],
   "source": [
    "csv_saver.log_candidates(second_res, bayesopt.config)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
