{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7cedb7f8",
   "metadata": {},
   "source": [
    "# BASIC CANDIDATE EXECUTION WITH YPROV4ML"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e3a31c2",
   "metadata": {},
   "source": [
    "Imports needed for BayesianOptimization and candidates generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "57c3bc11",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "98b3c3db",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys, os\n",
    "sys.path.insert(0, os.path.abspath(os.path.join(os.path.join(os.getcwd()), '..')))\n",
    "from bayesopt.bayesian_handler import BayesianOptimizer, OptimizationResults\n",
    "from bayesopt.config import OptimizationConfig\n",
    "import etl.extractors.provenance_extractor as pe\n",
    "from typing import Dict, List, Optional\n",
    "import csv\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73377354",
   "metadata": {},
   "source": [
    "### CANDIDATE GENERATION\n",
    "Here we use the run method to perform Bayesian Optimization and obtain two candidates.\n",
    "\n",
    "(for detailed explanation of the workflow in run method see detailed_cand_generation.ipynb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "da72a5b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   -> Starting Bayesian Optimization\n",
      "   -> Data transformed\n",
      "   -> Bounds generated\n",
      "   -> Data normalized\n",
      "   -> Model trained\n",
      "   -> Candidates obtained\n",
      "   -> Candidates denormalized\n",
      "   -> Bayesian Optimization finished, took 2.356s\n",
      "┌───────────┬──────────────┬───────────┬──────────┬─────────────────┐\n",
      "│   DROPOUT │   BATCH_SIZE │    EPOCHS │       LR │      MODEL_SIZE │\n",
      "├───────────┼──────────────┼───────────┼──────────┼─────────────────┤\n",
      "│  0.498842 │    31.001262 │ 10.000000 │ 0.091509 │ 10067992.975564 │\n",
      "└───────────┴──────────────┴───────────┴──────────┴─────────────────┘\n",
      "   -> Estimating candidates\n",
      "============================================================\n",
      "CANDIDATE 1\n",
      "============================================================\n",
      "┌───────────┬──────────┬──────────┐\n",
      "│ METRIC    │     MEAN │      STD │\n",
      "├───────────┼──────────┼──────────┤\n",
      "│ accuracy  │ 0.737888 │ 0.017957 │\n",
      "├───────────┼──────────┼──────────┤\n",
      "│ emissions │ 0.004369 │ 0.000388 │\n",
      "└───────────┴──────────┴──────────┘ \n",
      "\n"
     ]
    }
   ],
   "source": [
    "data_needed = {\n",
    "    'input': ['DROPOUT', 'BATCH_SIZE', 'EPOCHS', 'LR', 'MODEL_SIZE'],\n",
    "    'output': ['accuracy', 'emissions']\n",
    "}\n",
    "extractor = pe.ProvenanceExtractor('../test/prov_25', data_needed)\n",
    "inp, out = extractor.extract_all()      # cols are parameters/metrics, rows are runs\n",
    "\n",
    "bayesopt = BayesianOptimizer(OptimizationConfig(\n",
    "    data_needed['output'],\n",
    "    data_needed['input'],\n",
    "    ['MAX', 'MIN'],\n",
    "    ground_truth_dim=len(inp),\n",
    "    n_candidates=1,\n",
    "    n_restarts=10,\n",
    "    raw_samples=200,\n",
    "    optimizers='optimize_acqf',\n",
    "    acqf='ucb',\n",
    "    beta=1.5,\n",
    "    verbose=True\n",
    "))\n",
    "\n",
    "data = {\n",
    "    'parameters': inp,\n",
    "    'metrics': out\n",
    "}\n",
    "\n",
    "res = bayesopt.run(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9fdd9b5",
   "metadata": {},
   "source": [
    "### CANDIDATE EXECUTION\n",
    "In this block the candidate will be executed with yprov4ml (to see the yprov functionality refer to their documentation). \n",
    "\n",
    "NB: for now if the candidate generated has a twin there could be errors in returning the accuracy and emissions, if you notice a 'duplicate candidate' please change the _0 to _1 in the _emission call"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9aae5a39",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[codecarbon WARNING @ 11:47:23] Multiple instances of codecarbon are allowed to run at the same time.\n",
      "100%|██████████| 1613/1613 [06:26<00:00,  4.17it/s]\n",
      "100%|██████████| 1613/1613 [09:39<00:00,  2.78it/s]\n",
      "100%|██████████| 1613/1613 [09:24<00:00,  2.86it/s]\n",
      "100%|██████████| 1613/1613 [09:30<00:00,  2.83it/s]\n",
      "100%|██████████| 1613/1613 [07:46<00:00,  3.46it/s]\n",
      "100%|██████████| 1613/1613 [03:33<00:00,  7.57it/s]\n",
      "100%|██████████| 1613/1613 [09:53<00:00,  2.72it/s]\n",
      "100%|██████████| 1613/1613 [09:53<00:00,  2.72it/s]\n",
      "100%|██████████| 1613/1613 [09:53<00:00,  2.72it/s]\n",
      "100%|██████████| 1613/1613 [09:54<00:00,  2.71it/s]\n",
      "100%|██████████| 323/323 [00:30<00:00, 10.61it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 10.0 %\n",
      "Emissions: 0.17445367574691772\n"
     ]
    }
   ],
   "source": [
    "import torch, torchvision, yprov4ml\n",
    "import torch.optim as optim\n",
    "from tqdm import tqdm\n",
    "import torchvision.transforms as transforms\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import netCDF4 as nc\n",
    "\n",
    "class Net(nn.Module):\n",
    "    def __init__(self, model_size, dropout):\n",
    "        super(Net, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(3, 32, 3, 1)\n",
    "        self.conv2 = nn.Conv2d(32, 64, 3, 1)\n",
    "        self.dropout1 = nn.Dropout(dropout)\n",
    "        self.dropout2 = nn.Dropout(dropout)\n",
    "\n",
    "        def get_layer_sizes(model_size): \n",
    "            if model_size == \"small\": \n",
    "                return 64, 32\n",
    "            elif model_size == \"medium\": \n",
    "                return 512, 256\n",
    "            else: \n",
    "                return 1024, 256\n",
    "\n",
    "        l1, l2 = get_layer_sizes(model_size)\n",
    "\n",
    "        self.fc1 = nn.Linear(12544, l1)\n",
    "        self.fc2 = nn.Linear(l1, l2)\n",
    "        self.fc3 = nn.Linear(l2, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.conv2(x)\n",
    "        x = F.relu(x)\n",
    "        x = F.max_pool2d(x, 2)\n",
    "        x = self.dropout1(x)\n",
    "        x = torch.flatten(x, 1)\n",
    "        x = self.fc1(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.dropout2(x)\n",
    "        x = self.fc2(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.dropout1(x)\n",
    "        x = self.fc3(x)\n",
    "        output = F.log_softmax(x, dim=1)\n",
    "        return output\n",
    "\n",
    "def train(lr, epochs, batch_size, dropout, model_size):\n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "    transform = transforms.Compose([transforms.ToTensor(), transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])\n",
    "    dataset = torchvision.datasets.CIFAR10(root='./data', train=True, download=True, transform=transform)\n",
    "    trainloader = torch.utils.data.DataLoader(dataset, batch_size=batch_size)\n",
    "\n",
    "    model = Net(model_size, dropout=dropout).to(device)\n",
    "    optimizer = optim.Adam(model.parameters(), lr=lr)\n",
    "    criterion = torch.nn.CrossEntropyLoss().to(device)\n",
    "    scheduler = None\n",
    "\n",
    "    model.train()\n",
    "\n",
    "    losses = []\n",
    "    for _ in range(epochs): \n",
    "        for data in tqdm(trainloader):\n",
    "            inputs, labels = data[0].to(device), data[1].to(device)\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            losses.append(loss.item())\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            if scheduler is not None:\n",
    "                scheduler.step()\n",
    "    yprov4ml.log_carbon_metrics(yprov4ml.Context.TRAINING, step=0)\n",
    "    return model\n",
    "\n",
    "def emissions_(expdir_path):\n",
    "    fp=f'./{expdir_path}/metrics_GR0/emissions_Context.TRAINING_GR0.nc'\n",
    "    data = nc.Dataset(fp)\n",
    "    return data[\"values\"][:]\n",
    "\n",
    "def validate(model, batch_size=128):\n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "    transform = transforms.Compose([transforms.ToTensor(), transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])\n",
    "    dataset = torchvision.datasets.CIFAR10(root='./data', train=False, download=True, transform=transform)\n",
    "    testloader = torch.utils.data.DataLoader(dataset, batch_size=batch_size, shuffle=False)\n",
    "    model.eval()\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    with torch.no_grad():\n",
    "        for data in tqdm(testloader):\n",
    "            images, labels = data[0].to(device), data[1].to(device)\n",
    "            outputs = model(images)\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "\n",
    "    return correct / total\n",
    "\n",
    "def handle_modelsize(n: float):\n",
    "    if n <= 3700506.0:      #small\n",
    "        return 'small'\n",
    "    elif n <= 9853386.0:    #medium\n",
    "        return 'medium'\n",
    "    else:                   #large\n",
    "        return 'large'\n",
    "\n",
    "exec_results = []\n",
    "for candidate in res.candidates:\n",
    "    candidate[4] = handle_modelsize(candidate[4])\n",
    "    yprov4ml.start_run(\n",
    "        prov_user_namespace=\"www.example.org\",\n",
    "        experiment_name=f\"{round(candidate[3], 4)}_{int(candidate[2])}_{int(candidate[1])}_{round(candidate[0], 2)}_{candidate[4]}\", \n",
    "        provenance_save_dir=\"../test/prov_candidates_executed\",     # change the folder in which you want to save the candidate executed\n",
    "        save_after_n_logs=100,\n",
    "        collect_all_processes=False, \n",
    "        disable_codecarbon=False, \n",
    "        metrics_file_type=yprov4ml.MetricsType.NETCDF,\n",
    "    )\n",
    "\n",
    "    yprov4ml.log_param(\"MODEL_SIZE\", candidate[4], yprov4ml.Context.TRAINING)\n",
    "    yprov4ml.log_param(\"DROPOUT\", candidate[0], yprov4ml.Context.TRAINING)\n",
    "    yprov4ml.log_param(\"BATCH_SIZE\", candidate[1], yprov4ml.Context.TRAINING)\n",
    "    yprov4ml.log_param(\"EPOCHS\", candidate[2], yprov4ml.Context.TRAINING)\n",
    "    yprov4ml.log_param(\"LR\", candidate[3], yprov4ml.Context.TRAINING)\n",
    "\n",
    "    trained_model = train(candidate[3], int(candidate[2]), int(candidate[1]), candidate[0], candidate[4])\n",
    "    acc = validate(trained_model, int(candidate[1]))\n",
    "\n",
    "    yprov4ml.log_param(\"accuracy\", acc, yprov4ml.Context.TESTING)\n",
    "\n",
    "    yprov4ml.end_run(\n",
    "        create_graph=False,\n",
    "        create_svg=False,\n",
    "        crate_ro_crate=False\n",
    "    )\n",
    "\n",
    "    print(f'Accuracy: {100 * acc} %')\n",
    "    em = emissions_(f\"../test/prov_candidates_executed/{round(candidate[3], 4)}_{int(candidate[2])}_{int(candidate[1])}_{round(candidate[0], 2)}_{candidate[4]}_0\")[0]\n",
    "    print(f'Emissions: {em}')\n",
    "    exec_results.append([acc, em])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9f3fe7bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CSVResults:\n",
    "    \"\"\"class to write to a csv file the results obtained from Bayesian Optimization\n",
    "    \n",
    "    Attributes:\n",
    "        csv_path (str): path for the file to be accessed/created\n",
    "        parameter_names (List(str)): names of the parameters optimized (for headers)\n",
    "        metrics_names (List(str)): names of the metrics (for headers)\n",
    "        metrics_estim_names (List(str)): names of the estimated metrics (for headers)\n",
    "    \"\"\"\n",
    "    def __init__(self, headers: Dict[str, List[str]], path: str):\n",
    "        self.csv_path = path\n",
    "        self.parameter_names = headers['parameters']\n",
    "        self.metrics_names = headers['metrics']\n",
    "        self.metrics_estim_names = [f'estimated {m}' for m in headers['metrics']]\n",
    "        self.ensure_exists()\n",
    "\n",
    "    def build_headers(self):\n",
    "        headers = ['timestamp', 'candidate_id', 'acq_value', 'optimizer', 'acqf', 'n_restarts', 'raw_samples']\n",
    "\n",
    "        headers.extend(self.parameter_names)\n",
    "\n",
    "        for metric in self.metrics_estim_names:\n",
    "            headers.append(f'{metric} (mean)')\n",
    "            headers.append(f'{metric} (std)')\n",
    "\n",
    "        headers.append('execution status')\n",
    "        headers.extend(self.metrics_names)\n",
    "        return headers\n",
    "\n",
    "    def ensure_exists(self):\n",
    "        if not os.path.exists(self.csv_path):\n",
    "            with open(self.csv_path, 'w', newline='') as f:\n",
    "                writer = csv.writer(f)\n",
    "                writer.writerow(self.build_headers())\n",
    "    \n",
    "    def log_candidates(self, results: OptimizationResults, config: OptimizationConfig, exec_results: Optional[List[List]]=None):\n",
    "        timestamp = datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\")\n",
    "\n",
    "        # shape [n_candidates x n_metrics]\n",
    "        mean = results.posterior.mean.detach().numpy()\n",
    "        std = results.posterior.variance.sqrt().detach().numpy()\n",
    "\n",
    "        rows_to_write = []\n",
    "\n",
    "        if isinstance(results.acq_values, list):\n",
    "            acq_val = results.acq_values\n",
    "        else:\n",
    "            acq_val = [results.acq_values]*len(results.candidates)\n",
    "\n",
    "        for i, candidate in enumerate(results.candidates):\n",
    "            if isinstance(candidate, torch.Tensor):\n",
    "                candidate = candidate.tolist()\n",
    "\n",
    "            row = [timestamp, i+1, round(acq_val[i], 6), config.optimizers, config.acqf, config.n_restarts, config.raw_samples]\n",
    "            for param_val in candidate:\n",
    "                if isinstance(param_val, float):\n",
    "                    row.append(round(param_val, 6))\n",
    "                else:\n",
    "                    row.append(param_val)\n",
    "\n",
    "            for m in range(len(self.metrics_estim_names)):\n",
    "                if m < mean.shape[1]:\n",
    "                    row.append(round(mean[i][m].item(), 6))\n",
    "                    row.append(round(std[i][m].item(), 6))\n",
    "                else:\n",
    "                    row.extend([None, None])\n",
    "            \n",
    "            if exec_results and i < len(exec_results):\n",
    "                row.append('executed')\n",
    "                for m in range(len(self.metrics_names)):\n",
    "                    value = exec_results[i][m]\n",
    "                    if isinstance(value, float):\n",
    "                        row.append(round(value, 6))\n",
    "                    else:\n",
    "                        row.append(value)\n",
    "            else:\n",
    "                row.append('not_executed')\n",
    "                row.extend([None]*len(self.metrics_names))\n",
    "            \n",
    "            rows_to_write.append(row)\n",
    "\n",
    "        self.append_rows(rows_to_write)\n",
    "\n",
    "    def append_rows(self, rows: List[List]):\n",
    "        with open(self.csv_path, 'a', newline='') as f:\n",
    "            writer = csv.writer(f)\n",
    "            writer.writerows(rows)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "88d6972b",
   "metadata": {},
   "outputs": [],
   "source": [
    "csv_saver = CSVResults(\n",
    "    {'parameters': ['DROPOUT', 'BATCH_SIZE', 'EPOCHS', 'LR', 'MODEL_SIZE'], \n",
    "    'metrics': ['accuracy', 'emissions']},\n",
    "    './candidates_executed.csv')\n",
    "csv_saver.log_candidates(res, bayesopt.config, exec_results)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "035c4db6",
   "metadata": {},
   "source": [
    "In the following table we can observe the results obtained by generate, estimate and execute candidates.\n",
    "\n",
    "NB: the estimated emission is negative because it's a metric to minimize (so we have to consider it as positive)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "08d467b0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>timestamp</th>\n",
       "      <th>candidate_id</th>\n",
       "      <th>acq_value</th>\n",
       "      <th>optimizer</th>\n",
       "      <th>acqf</th>\n",
       "      <th>n_restarts</th>\n",
       "      <th>raw_samples</th>\n",
       "      <th>DROPOUT</th>\n",
       "      <th>BATCH_SIZE</th>\n",
       "      <th>EPOCHS</th>\n",
       "      <th>LR</th>\n",
       "      <th>MODEL_SIZE</th>\n",
       "      <th>estimated accuracy (mean)</th>\n",
       "      <th>estimated accuracy (std)</th>\n",
       "      <th>estimated emissions (mean)</th>\n",
       "      <th>estimated emissions (std)</th>\n",
       "      <th>execution status</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>emissions</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2025-12-30 13:14:09</td>\n",
       "      <td>1</td>\n",
       "      <td>0.377749</td>\n",
       "      <td>optimize_acqf</td>\n",
       "      <td>ucb</td>\n",
       "      <td>10</td>\n",
       "      <td>200</td>\n",
       "      <td>0.498842</td>\n",
       "      <td>31.001262</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0.091509</td>\n",
       "      <td>large</td>\n",
       "      <td>0.737888</td>\n",
       "      <td>0.017957</td>\n",
       "      <td>-0.004369</td>\n",
       "      <td>0.000388</td>\n",
       "      <td>executed</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.174454</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             timestamp  candidate_id  acq_value      optimizer acqf  \\\n",
       "0  2025-12-30 13:14:09             1   0.377749  optimize_acqf  ucb   \n",
       "\n",
       "   n_restarts  raw_samples   DROPOUT  BATCH_SIZE  EPOCHS        LR MODEL_SIZE  \\\n",
       "0          10          200  0.498842   31.001262    10.0  0.091509      large   \n",
       "\n",
       "   estimated accuracy (mean)  estimated accuracy (std)  \\\n",
       "0                   0.737888                  0.017957   \n",
       "\n",
       "   estimated emissions (mean)  estimated emissions (std) execution status  \\\n",
       "0                   -0.004369                   0.000388         executed   \n",
       "\n",
       "   accuracy  emissions  \n",
       "0       0.1   0.174454  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv('./candidates_executed.csv')\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "b266d9f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   -> Starting Bayesian Optimization\n",
      "   -> Model trained\n",
      "   -> Candidates obtained\n",
      "   -> Candidates denormalized\n",
      "   -> Bayesian Optimization finished, took 1.119s\n",
      "┌───────────┬──────────────┬───────────┬──────────┬─────────────────┐\n",
      "│   DROPOUT │   BATCH_SIZE │    EPOCHS │       LR │      MODEL_SIZE │\n",
      "├───────────┼──────────────┼───────────┼──────────┼─────────────────┤\n",
      "│  0.508000 │    28.299144 │ 10.263058 │ 0.000100 │ 11235063.540247 │\n",
      "└───────────┴──────────────┴───────────┴──────────┴─────────────────┘\n",
      "   -> Estimating candidates\n",
      "============================================================\n",
      "CANDIDATE 1\n",
      "============================================================\n",
      "┌───────────┬───────────┬──────────┐\n",
      "│ METRIC    │      MEAN │      STD │\n",
      "├───────────┼───────────┼──────────┤\n",
      "│ accuracy  │  0.687663 │ 0.100203 │\n",
      "├───────────┼───────────┼──────────┤\n",
      "│ emissions │ -0.028220 │ 0.041310 │\n",
      "└───────────┴───────────┴──────────┘ \n",
      "\n"
     ]
    }
   ],
   "source": [
    "model_size = 824862.0 if res.candidates[0][4] == 'small' else 6576330.0 if res.candidates[0][4] == 'medium' else 13130442.0\n",
    "new_data = {\n",
    "    'parameters': [[res.candidates[0][0], res.candidates[0][1], res.candidates[0][2], res.candidates[0][3], model_size]],\n",
    "    'metrics': exec_results\n",
    "}\n",
    "\n",
    "bayesopt.update_training_set(new_data)\n",
    "second_res = bayesopt.run()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
