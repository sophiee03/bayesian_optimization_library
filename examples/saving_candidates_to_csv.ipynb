{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a6188544",
   "metadata": {},
   "source": [
    "# GENERATE CANDIDATES ITERATIVELY"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "189a9e33",
   "metadata": {},
   "source": [
    "In this notebook we will generate candidates, execute them and append them to the training data at each iteration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e6a4c026",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d946172",
   "metadata": {},
   "source": [
    "Imports needed:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "67491a98",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys, os\n",
    "sys.path.insert(0, os.path.abspath(os.path.join(os.path.join(os.getcwd()), '..')))\n",
    "from bayesopt_core.bayesian_handler import BayesianOptimizer\n",
    "from bayesopt_core.config import OptimizationConfig\n",
    "import bayesopt_core.helpers.results_to_csv as csvres\n",
    "import etl.extractors.provenance_extractor as pe\n",
    "import torch, torchvision, yprov4ml\n",
    "import torch.optim as optim\n",
    "from tqdm import tqdm\n",
    "import torchvision.transforms as transforms\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import netCDF4 as nc"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ac4b00f",
   "metadata": {},
   "source": [
    "Initializations for training data retrieving and bayesian optimization configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "742af890",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_needed = {\n",
    "    'input': ['DROPOUT', 'BATCH_SIZE', 'LR'],\n",
    "    'output': ['accuracy', 'emissions']\n",
    "}\n",
    "extractor = pe.ProvenanceExtractor('../test/small_prov', data_needed)\n",
    "inp, out = extractor.extract_all()      # cols are parameters/metrics, rows are runs\n",
    "\n",
    "bayesopt = BayesianOptimizer(OptimizationConfig(\n",
    "    data_needed['output'],\n",
    "    data_needed['input'],\n",
    "    ['MAX', 'MIN'],\n",
    "    n_candidates=1,\n",
    "    n_restarts=10,\n",
    "    raw_samples=200,\n",
    "    optimizers='optimize_acqf',\n",
    "    acqf='ucb',\n",
    "    beta=1.5,\n",
    "    verbose=True\n",
    "))\n",
    "\n",
    "data = {\n",
    "    'parameters': inp,\n",
    "    'metrics': out\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a413642b",
   "metadata": {},
   "source": [
    "Initialization of classes and functions to execute yprov4ml with the candidates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ef25d249",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net(nn.Module):\n",
    "    def __init__(self, model_size, dropout):\n",
    "        super(Net, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(3, 32, 3, 1)\n",
    "        self.conv2 = nn.Conv2d(32, 64, 3, 1)\n",
    "        self.dropout1 = nn.Dropout(dropout)\n",
    "        self.dropout2 = nn.Dropout(dropout)\n",
    "\n",
    "        def get_layer_sizes(model_size): \n",
    "            if model_size == \"small\": \n",
    "                return 64, 32\n",
    "            elif model_size == \"medium\": \n",
    "                return 512, 256\n",
    "            else: \n",
    "                return 1024, 256\n",
    "\n",
    "        l1, l2 = get_layer_sizes(model_size)\n",
    "\n",
    "        self.fc1 = nn.Linear(12544, l1)\n",
    "        self.fc2 = nn.Linear(l1, l2)\n",
    "        self.fc3 = nn.Linear(l2, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.conv2(x)\n",
    "        x = F.relu(x)\n",
    "        x = F.max_pool2d(x, 2)\n",
    "        x = self.dropout1(x)\n",
    "        x = torch.flatten(x, 1)\n",
    "        x = self.fc1(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.dropout2(x)\n",
    "        x = self.fc2(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.dropout1(x)\n",
    "        x = self.fc3(x)\n",
    "        output = F.log_softmax(x, dim=1)\n",
    "        return output\n",
    "\n",
    "def train(lr, epochs, batch_size, dropout, model_size):\n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "    transform = transforms.Compose([transforms.ToTensor(), transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])\n",
    "    dataset = torchvision.datasets.CIFAR10(root='./data', train=True, download=True, transform=transform)\n",
    "    trainloader = torch.utils.data.DataLoader(dataset, batch_size=batch_size)\n",
    "\n",
    "    model = Net(model_size, dropout=dropout).to(device)\n",
    "    optimizer = optim.Adam(model.parameters(), lr=lr)\n",
    "    criterion = torch.nn.CrossEntropyLoss().to(device)\n",
    "    scheduler = None\n",
    "\n",
    "    model.train()\n",
    "\n",
    "    losses = []\n",
    "    for _ in range(epochs): \n",
    "        for data in tqdm(trainloader):\n",
    "            inputs, labels = data[0].to(device), data[1].to(device)\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            losses.append(loss.item())\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            if scheduler is not None:\n",
    "                scheduler.step()\n",
    "    yprov4ml.log_carbon_metrics(yprov4ml.Context.TRAINING, step=0)\n",
    "    return model\n",
    "\n",
    "def emissions_(expdir_path):\n",
    "    fp=f'./{expdir_path}/metrics_GR0/emissions_Context.TRAINING_GR0.nc'\n",
    "    data = nc.Dataset(fp)\n",
    "    return data[\"values\"][:]\n",
    "\n",
    "def validate(model, batch_size=128):\n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "    transform = transforms.Compose([transforms.ToTensor(), transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])\n",
    "    dataset = torchvision.datasets.CIFAR10(root='./data', train=False, download=True, transform=transform)\n",
    "    testloader = torch.utils.data.DataLoader(dataset, batch_size=batch_size, shuffle=False)\n",
    "    model.eval()\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    with torch.no_grad():\n",
    "        for data in tqdm(testloader):\n",
    "            images, labels = data[0].to(device), data[1].to(device)\n",
    "            outputs = model(images)\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "\n",
    "    return correct / total\n",
    "\n",
    "def handle_modelsize(n: float | str):\n",
    "    if isinstance(n, float):\n",
    "        if n <= 3700506.0:      #small\n",
    "            return 'small'\n",
    "        elif n <= 9853386.0:    #medium\n",
    "            return 'medium'\n",
    "        else:                   #large\n",
    "            return 'large'\n",
    "    else:\n",
    "        if n == 'small':\n",
    "            return 824682.0\n",
    "        elif n == 'medium':\n",
    "            return 6576330.0\n",
    "        else: \n",
    "            return 13130442.0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93f9e877",
   "metadata": {},
   "source": [
    "Setup of the iteration number and iterative execution of:\n",
    "- candidate generation\n",
    "- candidate execution\n",
    "- candidate storing\n",
    "- candidate integration in the training dataset for next iteration\n",
    "\n",
    "NB: in this case the modelsize and epochs parameters will be set automatically to have small runs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "56a9b9d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of training dataset runs: 242\n",
      "   -> Starting Bayesian Optimization\n",
      "   -> Data transformed\n",
      "   -> Bounds generated\n",
      "   -> Data normalized\n",
      "   -> Model trained\n",
      "   -> Candidates obtained\n",
      "   -> Candidates denormalized\n",
      "   -> Bayesian Optimization finished, took 1.203s\n",
      "┌───────────┬──────────────┬──────────┐\n",
      "│   DROPOUT │   BATCH_SIZE │       LR │\n",
      "├───────────┼──────────────┼──────────┤\n",
      "│  0.092000 │    15.040000 │ 0.000183 │\n",
      "└───────────┴──────────────┴──────────┘\n",
      "   -> Estimating candidates\n",
      "============================================================\n",
      "CANDIDATE 1\n",
      "============================================================\n",
      "┌───────────┬──────────┬──────────┐\n",
      "│ METRIC    │     MEAN │      STD │\n",
      "├───────────┼──────────┼──────────┤\n",
      "│ accuracy  │ 0.689782 │ 0.075515 │\n",
      "├───────────┼──────────┼──────────┤\n",
      "│ emissions │ 0.005612 │ 0.000293 │\n",
      "└───────────┴──────────┴──────────┘ \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[codecarbon WARNING @ 17:17:44] Multiple instances of codecarbon are allowed to run at the same time.\n",
      "100%|██████████| 3334/3334 [01:20<00:00, 41.32it/s]\n",
      "100%|██████████| 3334/3334 [01:19<00:00, 42.06it/s]\n",
      "100%|██████████| 3334/3334 [01:24<00:00, 39.63it/s]\n",
      "100%|██████████| 3334/3334 [01:29<00:00, 37.33it/s]\n",
      "100%|██████████| 667/667 [00:06<00:00, 98.25it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 64.64999999999999 %\n",
      "Emissions: 0.011190276592969894\n",
      "Number of training dataset runs: 243\n",
      "   -> Starting Bayesian Optimization\n",
      "   -> Data transformed\n",
      "   -> Bounds generated\n",
      "   -> Data normalized\n",
      "   -> Model trained\n",
      "   -> Candidates obtained\n",
      "   -> Candidates denormalized\n",
      "   -> Bayesian Optimization finished, took 1.072s\n",
      "┌───────────┬──────────────┬──────────┐\n",
      "│   DROPOUT │   BATCH_SIZE │       LR │\n",
      "├───────────┼──────────────┼──────────┤\n",
      "│  0.165169 │    64.979200 │ 0.000921 │\n",
      "└───────────┴──────────────┴──────────┘\n",
      "   -> Estimating candidates\n",
      "============================================================\n",
      "CANDIDATE 1\n",
      "============================================================\n",
      "┌───────────┬───────────┬──────────┐\n",
      "│ METRIC    │      MEAN │      STD │\n",
      "├───────────┼───────────┼──────────┤\n",
      "│ accuracy  │  0.663099 │ 0.077890 │\n",
      "├───────────┼───────────┼──────────┤\n",
      "│ emissions │ -0.003222 │ 0.002500 │\n",
      "└───────────┴───────────┴──────────┘ \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 782/782 [01:14<00:00, 10.49it/s]\n",
      "100%|██████████| 782/782 [01:14<00:00, 10.47it/s]\n",
      "100%|██████████| 782/782 [01:14<00:00, 10.48it/s]\n",
      "100%|██████████| 782/782 [01:14<00:00, 10.50it/s]\n",
      "100%|██████████| 157/157 [00:06<00:00, 23.03it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 67.75999999999999 %\n",
      "Emissions: 0.009664514102041721\n",
      "Number of training dataset runs: 244\n",
      "   -> Starting Bayesian Optimization\n",
      "   -> Data transformed\n",
      "   -> Bounds generated\n",
      "   -> Data normalized\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   -> Model trained\n",
      "   -> Candidates obtained\n",
      "   -> Candidates denormalized\n",
      "   -> Bayesian Optimization finished, took 1.124s\n",
      "┌───────────┬──────────────┬──────────┐\n",
      "│   DROPOUT │   BATCH_SIZE │       LR │\n",
      "├───────────┼──────────────┼──────────┤\n",
      "│  0.508160 │    65.977984 │ 0.000787 │\n",
      "└───────────┴──────────────┴──────────┘\n",
      "   -> Estimating candidates\n",
      "============================================================\n",
      "CANDIDATE 1\n",
      "============================================================\n",
      "┌───────────┬──────────┬──────────┐\n",
      "│ METRIC    │     MEAN │      STD │\n",
      "├───────────┼──────────┼──────────┤\n",
      "│ accuracy  │ 0.621479 │ 0.092438 │\n",
      "├───────────┼──────────┼──────────┤\n",
      "│ emissions │ 0.003870 │ 0.002523 │\n",
      "└───────────┴──────────┴──────────┘ \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 770/770 [01:12<00:00, 10.64it/s]\n",
      "100%|██████████| 770/770 [01:14<00:00, 10.32it/s]\n",
      "100%|██████████| 770/770 [01:14<00:00, 10.32it/s]\n",
      "100%|██████████| 770/770 [01:14<00:00, 10.37it/s]\n",
      "100%|██████████| 154/154 [00:05<00:00, 25.79it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 58.84 %\n",
      "Emissions: 0.00966402143239975\n",
      "executed 3 candidates\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "n=3\n",
    "for it in range(n):\n",
    "    print(f'Number of training dataset runs: {len(data['parameters'])}')\n",
    "    res = bayesopt.run(data) \n",
    "\n",
    "    exec_res = []\n",
    "    for candidate in res.candidates:\n",
    "        #candidate[4] = handle_modelsize(candidate[4])\n",
    "        yprov4ml.start_run(\n",
    "            prov_user_namespace=\"www.example.org\",\n",
    "            experiment_name=f\"{round(candidate[2], 4)}_4_{int(candidate[1])}_{round(candidate[0], 2)}_small\",\n",
    "            provenance_save_dir=\"../test/prov_iterative_candidates_executed\",     # change the folder in which you want to save the candidate executed\n",
    "            save_after_n_logs=100,\n",
    "            collect_all_processes=False, \n",
    "            disable_codecarbon=False, \n",
    "            metrics_file_type=yprov4ml.MetricsType.NETCDF,\n",
    "        )\n",
    "\n",
    "        yprov4ml.log_param(\"MODEL_SIZE\", 'small', yprov4ml.Context.TRAINING)\n",
    "        yprov4ml.log_param(\"DROPOUT\", candidate[0], yprov4ml.Context.TRAINING)\n",
    "        yprov4ml.log_param(\"BATCH_SIZE\", candidate[1], yprov4ml.Context.TRAINING)\n",
    "        yprov4ml.log_param(\"EPOCHS\", 4, yprov4ml.Context.TRAINING)\n",
    "        yprov4ml.log_param(\"LR\", candidate[2], yprov4ml.Context.TRAINING)\n",
    "\n",
    "        trained_model = train(candidate[2], 4, int(candidate[1]), candidate[0], 'small')\n",
    "        acc = validate(trained_model, int(candidate[1]))\n",
    "\n",
    "        yprov4ml.log_param(\"accuracy\", acc, yprov4ml.Context.TESTING)\n",
    "\n",
    "        yprov4ml.end_run(\n",
    "            create_graph=False,\n",
    "            create_svg=False,\n",
    "            crate_ro_crate=False\n",
    "        )\n",
    "\n",
    "        print(f'Accuracy: {100 * acc} %')\n",
    "        em = emissions_(f\"../test/prov_iterative_candidates_executed/{round(candidate[2], 4)}_4_{int(candidate[1])}_{round(candidate[0], 2)}_small_0\")[0]\n",
    "        print(f'Emissions: {em}')\n",
    "\n",
    "        exec_res.append([acc, em])\n",
    "\n",
    "        data['parameters'].append([candidate[0], candidate[1], candidate[2]])\n",
    "        data['metrics'].append([acc, em])\n",
    "\n",
    "    csv_saver = csvres.CSVResults(\n",
    "        {'parameters': ['DROPOUT', 'BATCH_SIZE', 'LR'], \n",
    "        'metrics': ['accuracy', 'emissions']},\n",
    "        './candidates_iterative_executed.csv')\n",
    "    csv_saver.log_candidates(res, bayesopt.config, exec_res)\n",
    "\n",
    "print(f\"executed {n*bayesopt.config.n_candidates} candidates\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
